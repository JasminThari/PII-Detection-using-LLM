{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import re\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from itertools import chain\n",
    "import ast\n",
    "from IPython.display import HTML\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc, Span\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "import string\n",
    "eng_tokenizer = English().tokenizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data in dictionary and dataframe format\n",
    "with open('../data/train.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data_df = pd.read_json('../data/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 6807\n"
     ]
    }
   ],
   "source": [
    "print('Number of documents:',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "data_df = data_df.rename(columns={'full_text':'text'})\n",
    "data_df['llm_generated'] = False\n",
    "data_df['prompt_id'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load llm generated data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load more data (llm generated)\n",
    "pii_dataset = pd.read_csv('../data/pii_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>job</th>\n",
       "      <th>address</th>\n",
       "      <th>username</th>\n",
       "      <th>url</th>\n",
       "      <th>hobby</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073d46f-2241-459b-ab01-851be8d26436</td>\n",
       "      <td>My name is Aaliyah Popova, and I am a jeweler ...</td>\n",
       "      <td>['My', 'name', 'is', 'Aaliyah', 'Popova,', 'an...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>['O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUD...</td>\n",
       "      <td>\\n    Aaliyah Popova is a jeweler with 13 year...</td>\n",
       "      <td>1</td>\n",
       "      <td>Aaliyah Popova</td>\n",
       "      <td>aaliyah.popova4783@aol.edu</td>\n",
       "      <td>(95) 94215-7906</td>\n",
       "      <td>jeweler</td>\n",
       "      <td>97 Lincoln Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Podcasting</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ec717a9-17ee-48cd-9d76-30ae256c9354</td>\n",
       "      <td>My name is Konstantin Becker, and I'm a develo...</td>\n",
       "      <td>['My', 'name', 'is', 'Konstantin', 'Becker,', ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>['O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUD...</td>\n",
       "      <td>\\n    Konstantin Becker is a developer with 2 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Konstantin Becker</td>\n",
       "      <td>konstantin.becker@gmail.com</td>\n",
       "      <td>0475 4429797</td>\n",
       "      <td>developer</td>\n",
       "      <td>826 Webster Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quilting</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               document  \\\n",
       "0  1073d46f-2241-459b-ab01-851be8d26436   \n",
       "1  5ec717a9-17ee-48cd-9d76-30ae256c9354   \n",
       "\n",
       "                                                text  \\\n",
       "0  My name is Aaliyah Popova, and I am a jeweler ...   \n",
       "1  My name is Konstantin Becker, and I'm a develo...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['My', 'name', 'is', 'Aaliyah', 'Popova,', 'an...   \n",
       "1  ['My', 'name', 'is', 'Konstantin', 'Becker,', ...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, True, True, True, Tru...   \n",
       "1  [True, True, True, True, True, True, True, Tru...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  ['O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUD...   \n",
       "1  ['O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUD...   \n",
       "\n",
       "                                              prompt  prompt_id  \\\n",
       "0  \\n    Aaliyah Popova is a jeweler with 13 year...          1   \n",
       "1  \\n    Konstantin Becker is a developer with 2 ...          1   \n",
       "\n",
       "                name                        email            phone        job  \\\n",
       "0     Aaliyah Popova   aaliyah.popova4783@aol.edu  (95) 94215-7906    jeweler   \n",
       "1  Konstantin Becker  konstantin.becker@gmail.com     0475 4429797  developer   \n",
       "\n",
       "              address username  url       hobby  len  \n",
       "0   97 Lincoln Street      NaN  NaN  Podcasting  363  \n",
       "1  826 Webster Street      NaN  NaN    Quilting  255  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 4434\n"
     ]
    }
   ],
   "source": [
    "print('Number of documents:',len(pii_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "pii_dataset['llm_generated'] = True\n",
    "\n",
    "# Convert string to list\n",
    "pii_dataset[[\"tokens\", \"trailing_whitespace\", \"labels\"]] = pii_dataset[[\"tokens\", \"trailing_whitespace\", \"labels\"]].map(ast.literal_eval)\n",
    "pii_dataset[\"document\"] = pii_dataset[\"document\"].astype(\"category\").cat.codes + (data_df.document.max() + 1) # make sure document id is unique and changing to int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize using spacy (to have same tokenizer as the original data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_spacy(text, tokenizer=eng_tokenizer):\n",
    "    tokenized_text = tokenizer(text)\n",
    "    tokens = [token.text for token in tokenized_text]\n",
    "    trailing_whitespace = [bool(token.whitespace_) for token in tokenized_text]\n",
    "    return {'tokens': tokens, 'trailing_whitespace': trailing_whitespace}\n",
    "\n",
    "def create_new_tokens_labels(row):\n",
    "    \n",
    "    tokens, labels, trailing_whitespace = row.tokens, row.labels, row.trailing_whitespace\n",
    "    new_tokens, new_labels, new_trailing_whitespaces = [], [], []\n",
    "    labels = [l.split(\"-\")[1] if l != \"O\" else l for l in labels]\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        t = tokens[i]\n",
    "        l = labels[i]\n",
    "        ws = trailing_whitespace[i]\n",
    "        \n",
    "        prev_l = labels[i - 1] if i > 0 else \"O\"\n",
    "        next_l = labels[i + 1] if (i + 1) < len(labels) else \"O\"\n",
    "        \n",
    "        # Found a PHONE_NUM token mislabed as STREET_ADDRESS:\n",
    "        if l != \"O\" and re.search(r'\\+\\d+', t):\n",
    "            l = \"PHONE_NUM\"\n",
    "        \n",
    "        # Found STREET_ADDRESS between 2 PHONE_NUM:\n",
    "        if l == \"STREET_ADDRESS\" and prev_l == \"PHONE_NUM\" and prev_l == next_l:\n",
    "            l = \"PHONE_NUM\"\n",
    "            \n",
    "        # Found individual mislabeled STREET_ADDRESS tokens:\n",
    "        elif l == \"STREET_ADDRESS\" and l != next_l and l != prev_l:\n",
    "            l = \"O\"\n",
    "        \n",
    "        # Create spacy tokens and their labels\n",
    "        tok_ = tokenize_with_spacy(t)\n",
    "        spacy_tokens = tok_[\"tokens\"]\n",
    "        new_tokens.extend(spacy_tokens)\n",
    "        \n",
    "        new_labels.extend([l if st not in string.punctuation else \"O\" for st in spacy_tokens])\n",
    "        \n",
    "        new_trailing_whitespaces.extend(tok_[\"trailing_whitespace\"])\n",
    "        new_trailing_whitespaces[-1] = ws  \n",
    "        \n",
    "    return pd.Series({\"document\": row.document, \"tokens\": new_tokens, \"trailing_whitespace\": new_trailing_whitespaces, \"labels\": new_labels})\n",
    "\n",
    "\n",
    "def update_labels(row):    \n",
    "    tokens = row.tokens\n",
    "    labels = row.labels\n",
    "    new_labels = [\"O\"] * len(labels)\n",
    "    for i, (t, l) in enumerate(zip(tokens, labels)):\n",
    "        prev_l = new_labels[i - 1] if i > 0 else \"O\"\n",
    "        next_l = labels[i + 1] if i + 1 < len(labels) else \"O\"\n",
    "    \n",
    "        if (prev_l == \"NAME_STUDENT\" or prev_l == \"O\") and t == \"'s\":\n",
    "            new_labels[i] = \"O\"\n",
    "\n",
    "        elif t == \"(\" and next_l == \"PHONE_NUM\":\n",
    "            new_labels[i] = next_l\n",
    "\n",
    "        elif t == \")\" and prev_l == \"PHONE_NUM\":\n",
    "            new_labels[i] = prev_l\n",
    "        \n",
    "        elif (t in string.punctuation) and (prev_l == next_l) and (prev_l != \"O\"):\n",
    "            \n",
    "            if t == \",\" and prev_l != \"STREET_ADDRESS\":\n",
    "                new_labels[i] = \"O\"\n",
    "            elif t == \".\" and prev_l == \"NAME_STUDENT\":\n",
    "                new_labels[i] = \"O\"\n",
    "            else:\n",
    "                new_labels[i] = prev_l\n",
    "        \n",
    "        else:\n",
    "            new_labels[i] = l\n",
    "    \n",
    "    return new_labels\n",
    "\n",
    "def create_bio_labels(labels):\n",
    "    new_labels = [\"O\"]*len(labels)\n",
    "    prev_l = \"O\"\n",
    "    for i, l in enumerate(labels):\n",
    "        if l != \"O\":\n",
    "            if l != prev_l:\n",
    "                new_labels[i] = \"B-\" + l\n",
    "            elif l == prev_l:\n",
    "                new_labels[i] = \"I-\" + l\n",
    "        prev_l = l\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pii_dataset = pii_dataset.apply(create_new_tokens_labels, axis=1)\n",
    "new_pii_dataset[\"labels\"] = new_pii_dataset.apply(update_labels, axis=1).apply(create_bio_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pii_dataset['text'] = new_pii_dataset['tokens'].apply(lambda x: ' '.join(x))\n",
    "new_pii_dataset[['prompt_id', 'llm_generated']] = pii_dataset[['prompt_id', 'llm_generated']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>llm_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22968</td>\n",
       "      <td>[My, name, is, Aaliyah, Popova, ,, and, I, am,...</td>\n",
       "      <td>[True, True, True, True, False, True, True, Tr...</td>\n",
       "      <td>[O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...</td>\n",
       "      <td>My name is Aaliyah Popova , and I am a jeweler...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24398</td>\n",
       "      <td>[My, name, is, Konstantin, Becker, ,, and, I, ...</td>\n",
       "      <td>[True, True, True, True, False, True, True, Fa...</td>\n",
       "      <td>[O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...</td>\n",
       "      <td>My name is Konstantin Becker , and I 'm a deve...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23632</td>\n",
       "      <td>[As, Mieko, Mitsubishi, ,, an, account, manage...</td>\n",
       "      <td>[True, True, False, True, True, True, True, Tr...</td>\n",
       "      <td>[O, B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O...</td>\n",
       "      <td>As Mieko Mitsubishi , an account manager at a ...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25282</td>\n",
       "      <td>[My, name, is, Kazuo, Sun, ,, and, I, 'm, an, ...</td>\n",
       "      <td>[True, True, True, True, False, True, True, Fa...</td>\n",
       "      <td>[O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...</td>\n",
       "      <td>My name is Kazuo Sun , and I 'm an air traffic...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                             tokens  \\\n",
       "0     22968  [My, name, is, Aaliyah, Popova, ,, and, I, am,...   \n",
       "1     24398  [My, name, is, Konstantin, Becker, ,, and, I, ...   \n",
       "2     23632  [As, Mieko, Mitsubishi, ,, an, account, manage...   \n",
       "3     25282  [My, name, is, Kazuo, Sun, ,, and, I, 'm, an, ...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, True, True, Tr...   \n",
       "1  [True, True, True, True, False, True, True, Fa...   \n",
       "2  [True, True, False, True, True, True, True, Tr...   \n",
       "3  [True, True, True, True, False, True, True, Fa...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...   \n",
       "1  [O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...   \n",
       "2  [O, B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O...   \n",
       "3  [O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...   \n",
       "\n",
       "                                                text  prompt_id  llm_generated  \n",
       "0  My name is Aaliyah Popova , and I am a jeweler...          1           True  \n",
       "1  My name is Konstantin Becker , and I 'm a deve...          1           True  \n",
       "2  As Mieko Mitsubishi , an account manager at a ...          3           True  \n",
       "3  My name is Kazuo Sun , and I 'm an air traffic...          1           True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pii_dataset.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two datasets\n",
    "df = pd.concat([data_df, new_pii_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>llm_generated</th>\n",
       "      <th>prompt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                               text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "\n",
       "                                              labels  llm_generated  prompt_id  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...          False         -1  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...          False         -1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(df):\n",
    "    df = df.copy()\n",
    "    df[\"unique_labels\"] = df[\"labels\"].apply(lambda x: set(\n",
    "        [l.split('-')[1] if l != 'O' else l for l in x]\n",
    "         ))\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    one_hot_encoded = mlb.fit_transform(df['unique_labels'])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=mlb.classes_)\n",
    "    df = pd.concat([df, one_hot_df], axis=1)\n",
    "    \n",
    "    # add 'OTHER' column which is only true when we have no other label in text\n",
    "    df['OTHER'] = df['unique_labels'].apply(lambda x: 1 if len(x - {\"O\"}) == 0 else 0)\n",
    "    \n",
    "    return df, list(mlb.classes_) + ['OTHER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, label_classes = encode_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>llm_generated</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>unique_labels</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>ID_NUM</th>\n",
       "      <th>NAME_STUDENT</th>\n",
       "      <th>O</th>\n",
       "      <th>PHONE_NUM</th>\n",
       "      <th>STREET_ADDRESS</th>\n",
       "      <th>URL_PERSONAL</th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>{NAME_STUDENT, O}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>{NAME_STUDENT, O}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                               text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "\n",
       "                                              labels  llm_generated  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...          False   \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...          False   \n",
       "\n",
       "   prompt_id      unique_labels  EMAIL  ID_NUM  NAME_STUDENT  O  PHONE_NUM  \\\n",
       "0         -1  {NAME_STUDENT, O}      0       0             1  1          0   \n",
       "1         -1  {NAME_STUDENT, O}      0       0             1  1          0   \n",
       "\n",
       "   STREET_ADDRESS  URL_PERSONAL  USERNAME  OTHER  \n",
       "0               0             0         0      0  \n",
       "1               0             0         0      0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['labels'].tolist()\n",
    "\n",
    "# Flatten the list of lists\n",
    "flattened_labels = list(itertools.chain.from_iterable(labels))\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = Counter(flattened_labels)\n",
    "\n",
    "# Separate the labels and their counts for plotting\n",
    "labels, counts = zip(*label_counts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar plot\n",
    "fig = go.Figure([go.Bar(x=labels[1:], y=counts[1:])])\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(title_text='Frequency of Each Label', xaxis_title='Labels', yaxis_title='Frequency')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique targets in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unique_labels'] = df['labels'].apply(lambda x: list(set(x)))\n",
    "df['num_labels'] = df['unique_labels'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of number of labels per document\n",
    "fig = px.histogram(df, x='num_labels', nbins=20, title='Histogram of number of unique labels per document')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of tokens in each document (with whitespace) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_tokens'] = df['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of number of tokens per document\n",
    "fig = px.histogram(df, x='num_tokens', nbins=500, title='Histogram of number of tokens per document')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_text'] = df['text'].apply(len)\n",
    "fig = px.histogram(df, x='len_text', nbins=500, title='Histogram of length of text per document')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of documents without labels(only \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_outer = df[df['labels'].apply(lambda x: len(set(x)) > 1)] #with labels\n",
    "df_outer = df[df['labels'].apply(lambda x: 'O' in x and len(set(x)) == 1)] #without labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_outer['Label Type'] = 'With Labels'\n",
    "df_outer['Label Type'] = 'Without Labels'\n",
    "\n",
    "# Calculate text length\n",
    "df['len_text'] = df['text'].apply(len)\n",
    "df_non_outer['len_text'] = df_non_outer['text'].apply(len)\n",
    "df_outer['len_text'] = df_outer['text'].apply(len)\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_df = pd.concat([df_non_outer, df_outer])\n",
    "\n",
    "# Plotting\n",
    "fig = px.histogram(combined_df, x='len_text', color='Label Type', barmode='overlay',\n",
    "                   nbins=500, title='Histogram of Length of Text per Document')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes\n",
    "combined_df = pd.concat([df_non_outer, df_outer])\n",
    "combined_df['len_tokens'] = combined_df['tokens'].apply(len)\n",
    "# Plotting\n",
    "fig = px.histogram(combined_df, x='len_tokens', color='Label Type', barmode='overlay',\n",
    "                   nbins=500, title='Histogram of Length of Tokens per Document')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"labels_pos\"] = df[\"labels\"].apply(lambda labels: np.arange(1, len(labels) + 1) / len(labels))\n",
    "exp_df = df.explode([\"tokens\", \"labels\", \"labels_pos\"])\n",
    "exp_df[\"labels\"] = pd.Categorical(exp_df[\"labels\"], categories=labels, ordered=True)\n",
    "exp_df = exp_df.sort_values(by=\"labels\", ascending=False)\n",
    "label_tokens = exp_df.groupby(\"labels\", observed=False).agg(list)\n",
    "label_tokens[\"counts\"] = label_tokens[\"tokens\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(exp_df, x='labels_pos', y='labels', title='Scatter Plot of Labels in Documents',)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='X Axis Label',\n",
    "    yaxis_title='Y Axis Label',\n",
    "    legend_title='Legend'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud for each target \n",
    "# wordcloud for surronding words of each target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "# wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df_train['full_text']))\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.imshow(wordcloud, interpolation='bilinear')\n",
    "# plt.axis('off')\n",
    "# plt.title('Word Cloud of Essays')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Visualization with Spacy of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_spacy_format(text, tokens, labels, trailing_whitespace):\n",
    "    ents = []  # To store entity dictionaries\n",
    "    start = 0  # Position tracker for the start of each token in the text\n",
    "    \n",
    "    for i, (token, label, space) in enumerate(zip(tokens, labels, trailing_whitespace)):\n",
    "        if label.startswith('B-') or label.startswith('I-'):\n",
    "            label_type = label[2:]  # Extract entity type from label\n",
    "            token_start = text.find(token, start)  # Find the start index of the token in text\n",
    "            token_end = token_start + len(token)  # Calculate the end index of the token\n",
    "            \n",
    "            # If it's a 'B-' label or the first 'I-' label following non-matching or 'O' labels, start a new entity\n",
    "            if label.startswith('B-') or (label.startswith('I-') and (i == 0 or not labels[i-1].endswith(label_type))):\n",
    "                ents.append({\"start\": token_start, \"end\": token_end, \"label\": label_type})\n",
    "            # If it's an 'I-' label continuing an entity, extend the last entity's end index\n",
    "            elif label.startswith('I-') and ents and ents[-1][\"label\"] == label_type:\n",
    "                ents[-1][\"end\"] = token_end\n",
    "            \n",
    "            start = token_end + (1 if space == 'True' else 0)  # Update start position for next token\n",
    "    \n",
    "    return [{\"text\": text, \"ents\": ents, \"title\": None}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ner(row):\n",
    "\n",
    "    display_text = row['text'].values[0] \n",
    "    display_labels = row['labels'].values[0] \n",
    "    trailing_whitespace = row['trailing_whitespace'].values[0] \n",
    "    tokens = row['tokens'].values[0] \n",
    "\n",
    "    display_text = display_text.replace(\"\\n\\n\", \"\\r\\n\")\n",
    "    ex = convert_to_spacy_format(display_text, tokens, display_labels, trailing_whitespace)\n",
    "\n",
    "    custom_css = \"\"\"\n",
    "                <style>    \n",
    "                    /* Customizing entity appearance */\n",
    "                    .entities {\n",
    "                        font-size: 11px !important;\n",
    "                        font-family: Verdana !important;\n",
    "                        line-height: 1.25 !important;\n",
    "                        border-radius: 10px !important; /* Rounded corners */\n",
    "                        background-color: #f9f9f9 !important; /* Very light gray background */\n",
    "                        padding: 20px 15px !important; /* Adjust padding */\n",
    "                    }\n",
    "                    /* Customizing entity appearance */\n",
    "                    .entity {\n",
    "                        font-size: 10px !important;\n",
    "                        padding: 0.2em 0.4em !important;\n",
    "                        font-family: Verdana !important;\n",
    "                        font-weight: bold !important;\n",
    "                        \n",
    "                    }\n",
    "                </style>\n",
    "                \"\"\"\n",
    "\n",
    "    options = {\"colors\": {\"NAME_STUDENT\": \"#748CAB\", \"URL_PERSONAL\": \"#FFFC31\", \n",
    "                        \"ID_NUM\": \"#E94F37\", \"EMAIL\": \"#F8B195\", \"STREET_ADDRESS\": \"#BDBF09\", \"PHONE_NUM\": \"#D96C06\", \"USERNAME\": \"#2292A4\"}}\n",
    "\n",
    "    # Inject custom CSS\n",
    "    display(HTML(custom_css))\n",
    "\n",
    "    spacy.displacy.render(ex, style=\"ent\", manual=True, jupyter=True, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <style>    \n",
       "                    /* Customizing entity appearance */\n",
       "                    .entities {\n",
       "                        font-size: 11px !important;\n",
       "                        font-family: Verdana !important;\n",
       "                        line-height: 1.25 !important;\n",
       "                        border-radius: 10px !important; /* Rounded corners */\n",
       "                        background-color: #f9f9f9 !important; /* Very light gray background */\n",
       "                        padding: 20px 15px !important; /* Adjust padding */\n",
       "                    }\n",
       "                    /* Customizing entity appearance */\n",
       "                    .entity {\n",
       "                        font-size: 10px !important;\n",
       "                        padding: 0.2em 0.4em !important;\n",
       "                        font-family: Verdana !important;\n",
       "                        font-weight: bold !important;\n",
       "                        \n",
       "                    }\n",
       "                </style>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #748CAB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Waseem Mabunda\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME_STUDENT</span>\n",
       "</mark>\n",
       "  \n",
       "<mark class=\"entity\" style=\"background: #BDBF09; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    591 Smith Centers Apt. 656\n",
       "Joshuamouth, RI 95963\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STREET_ADDRESS</span>\n",
       "</mark>\n",
       " ( The Netherlands)  \n",
       "<mark class=\"entity\" style=\"background: #D96C06; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    410.526.1667\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE_NUM</span>\n",
       "</mark>\n",
       "  vpi@mn.nl\r<br>Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\r<br>D e s i g n  T h i n k i n g\r<br>Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      \n",
       "<mark class=\"entity\" style=\"background: #FFFC31; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    https://www.youtube.com/watch?v=tIBN9VJ0S4a\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">URL_PERSONAL</span>\n",
       "</mark>\n",
       "    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\r<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <style>    \n",
       "                    /* Customizing entity appearance */\n",
       "                    .entities {\n",
       "                        font-size: 11px !important;\n",
       "                        font-family: Verdana !important;\n",
       "                        line-height: 1.25 !important;\n",
       "                        border-radius: 10px !important; /* Rounded corners */\n",
       "                        background-color: #f9f9f9 !important; /* Very light gray background */\n",
       "                        padding: 20px 15px !important; /* Adjust padding */\n",
       "                    }\n",
       "                    /* Customizing entity appearance */\n",
       "                    .entity {\n",
       "                        font-size: 10px !important;\n",
       "                        padding: 0.2em 0.4em !important;\n",
       "                        font-family: Verdana !important;\n",
       "                        font-weight: bold !important;\n",
       "                        \n",
       "                    }\n",
       "                </style>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As a veterinarian at the bustling Happy Tails Animal Clinic , my days are filled with furry companions and their devoted owners . From routine checkups to intricate surgeries , I strive to ensure the well - being of each animal that graces our doors . One particularly memorable case involved a beloved golden retriever named Buddy . Buddy 's owner , a young woman named Sarah , was deeply concerned about his persistent limp . After a thorough examination , I discovered a small thorn embedded in Buddy 's paw . Using my expertise and gentle touch , I carefully extracted the thorn , providing Buddy with immediate relief . The sight of Buddy frolicking pain - free in the park days later brought immense joy to both Sarah and me . The bond between humans and animals is truly remarkable , and it 's an honor to be a part of their journey . You can reach me at \n",
       "<mark class=\"entity\" style=\"background: #F8B195; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    christian-walker@hotmail.gov\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
       "</mark>\n",
       " or visit me at \n",
       "<mark class=\"entity\" style=\"background: #BDBF09; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5029 Montclair Drive\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STREET_ADDRESS</span>\n",
       "</mark>\n",
       " if you have any questions or concerns regarding your pet 's health .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <style>    \n",
       "                    /* Customizing entity appearance */\n",
       "                    .entities {\n",
       "                        font-size: 11px !important;\n",
       "                        font-family: Verdana !important;\n",
       "                        line-height: 1.25 !important;\n",
       "                        border-radius: 10px !important; /* Rounded corners */\n",
       "                        background-color: #f9f9f9 !important; /* Very light gray background */\n",
       "                        padding: 20px 15px !important; /* Adjust padding */\n",
       "                    }\n",
       "                    /* Customizing entity appearance */\n",
       "                    .entity {\n",
       "                        font-size: 10px !important;\n",
       "                        padding: 0.2em 0.4em !important;\n",
       "                        font-family: Verdana !important;\n",
       "                        font-weight: bold !important;\n",
       "                        \n",
       "                    }\n",
       "                </style>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My name is \n",
       "<mark class=\"entity\" style=\"background: #748CAB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kazuo Sun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME_STUDENT</span>\n",
       "</mark>\n",
       " , and I 'm an air traffic controller with seven years of experience . I 've always been fascinated by aviation , and I love the challenge of keeping planes safe and on time . One of the most memorable projects I worked on was a major upgrade to our airport 's radar system . The old system was outdated and prone to breakdowns , and it was becoming increasingly difficult to keep up with the growing number of flights . I was assigned to the team that was responsible for planning and implementing the upgrade . We worked closely with the engineers and technicians to design a new system that would be more reliable , efficient , and capable . The project took several months to complete , and it was a lot of hard work . But in the end , it was worth it . The new radar system has been a major improvement , and it has helped us to improve the safety and efficiency of our airport . I 'm proud of the work that I did on this project , and I 'm grateful for the opportunity to have been a part of it . It was a challenging experience , but it also taught me a lot about teamwork , problem - solving , and the importance of staying up - to - date on the latest technology . Outside of work , I enjoy spending time with my family and friends . I also enjoy amateur radio and tinkering with electronics . I 'm always looking for new projects to work on , and I 'm always learning new things . If you 'd like to get in touch with me , you can reach me by phone at \n",
       "<mark class=\"entity\" style=\"background: #D96C06; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0304 2215930\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE_NUM</span>\n",
       "</mark>\n",
       " or by email at \n",
       "<mark class=\"entity\" style=\"background: #F8B195; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    kazuosun@hotmail.net\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
       "</mark>\n",
       " . You can also find me at my home address , which is \n",
       "<mark class=\"entity\" style=\"background: #BDBF09; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    736 Sicard Street Southeast\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STREET_ADDRESS</span>\n",
       "</mark>\n",
       " .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_ner(df[df['document'] == 9854])\n",
    "visualize_ner(df.sort_values(by=[\"unique_labels\"], ascending=True).reset_index(drop=True).iloc[0:1])\n",
    "visualize_ner(df.sort_values(by=[\"num_labels\"], ascending=False).reset_index(drop=True).iloc[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word surronding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pii_data = {\n",
    "#     'EMAIL':{},\n",
    "#     'ID_NUM':{},\n",
    "#     'NAME_STUDENT':{},\n",
    "#     'PHONE_NUM':{},\n",
    "#     'STREET_ADDRESS':{},\n",
    "#     'URL_PERSONAL':{},\n",
    "#     'USERNAME':{},\n",
    "# }\n",
    "\n",
    "# def update_pii_data(pii_type, token, tokens, i):\n",
    "#     if pii_type not in pii_data:\n",
    "#         pii_data[pii_type] = {}\n",
    "    \n",
    "#     # Extracting the token and surrounding context\n",
    "#     token_text = tokens[i]\n",
    "#     surrounding_tokens = tokens[max(0, i-2):i] + tokens[i+1:min(len(tokens), i+3)]\n",
    "#     sentence = ' '.join(tokens)  # Simplified; consider a more accurate sentence detection\n",
    "    \n",
    "#     # Assuming `tokens` is a list of all tokens in the document and `i` is the index of the current token\n",
    "#     sentence_boundaries = [j for j, token in enumerate(tokens) if token in '.!?'] + [len(tokens)-1]\n",
    "#     sentence_start = max([boundary for boundary in sentence_boundaries if boundary < i]+[0])\n",
    "#     sentence_end = min([boundary for boundary in sentence_boundaries if boundary > i]+[len(tokens)-1])\n",
    "#     sentence_context = tokens[sentence_start:sentence_end+1]\n",
    "    \n",
    "#     # Determine PII position in the sentence\n",
    "#     position_in_sentence = \"middle\"\n",
    "#     if i == sentence_start:\n",
    "#         position_in_sentence = \"beginning\"\n",
    "#     elif i == sentence_end:\n",
    "#         position_in_sentence = \"end\"\n",
    "    \n",
    "#     # PII Token Type\n",
    "#     if token_text.isalpha():\n",
    "#         token_type = \"alphabetic\"\n",
    "#     elif token_text.isdigit():\n",
    "#         token_type = \"numeric\"\n",
    "#     else:\n",
    "#         token_type = \"alphanumeric\" if any(char.isalpha() for char in token_text) else \"other\"\n",
    "    \n",
    "#     # PII Format Pattern\n",
    "#     format_pattern = ''.join(['d' if char.isdigit() else 'l' if char.isalpha() else char for char in token_text])\n",
    "    \n",
    "#     # Capitalization\n",
    "#     capitalization = \"lowercase\"\n",
    "#     if token_text.isupper():\n",
    "#         capitalization = \"uppercase\"\n",
    "#     elif token_text.istitle():\n",
    "#         capitalization = \"titlecase\"\n",
    "    \n",
    "#     # Special Characters\n",
    "#     special_chars = any(not char.isalnum() for char in token_text)\n",
    "    \n",
    "#     details = {\n",
    "#         'token_text': token_text,\n",
    "#         'surrounding_words': surrounding_tokens,\n",
    "#         'location_in_essay': i,\n",
    "#         'sentence_context': ' '.join(sentence_context),\n",
    "#         'pii_length': len(token_text),\n",
    "#         'position_in_sentence': position_in_sentence,\n",
    "#         'token_type': token_type,\n",
    "#         'format_pattern': format_pattern,\n",
    "#         'capitalization': capitalization,\n",
    "#         'special_chars': special_chars,\n",
    "#         # Add more details as needed\n",
    "#     }\n",
    "    \n",
    "#     pii_token_key = f\"{token_text}_{i}\"  # Unique key for each PII instance\n",
    "#     if pii_token_key not in pii_data[pii_type]:\n",
    "#         pii_data[pii_type][pii_token_key] = []\n",
    "#     pii_data[pii_type][pii_token_key].append(details)\n",
    "\n",
    "# # Example of how to call this function within your iteration over the DataFrame\n",
    "# for index, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "#     tokens = row['tokens']\n",
    "#     labels = row['labels']\n",
    "#     for i, label in enumerate(labels):\n",
    "#         if label != 'O':  # If the label indicates PII\n",
    "#             pii_type = label[2:]  # Extract PII type (removing the B- or I- prefix)\n",
    "#             update_pii_data(pii_type, tokens[i], tokens, i)\n",
    "            \n",
    "            \n",
    "# # Initialize an empty list to hold each PII instance as a dictionary\n",
    "# flat_pii_data = []\n",
    "\n",
    "# # Iterate through the pii_data dictionary\n",
    "# for pii_type, pii_instances in pii_data.items():\n",
    "#     for instance_key, details_list in pii_instances.items():\n",
    "#         for details in details_list:\n",
    "#             # Create a flat dictionary for each PII instance\n",
    "#             flat_instance = details.copy()  # Start with the existing details\n",
    "#             flat_instance['pii_type'] = pii_type  # Add the PII type\n",
    "#             flat_instance['instance_key'] = instance_key  # Add the instance key for reference\n",
    "            \n",
    "#             # Append this flat dictionary to our list\n",
    "#             flat_pii_data.append(flat_instance)\n",
    "\n",
    "# # Store and viz\n",
    "# train_pii_df = pd.DataFrame(flat_pii_data)\n",
    "# print(\"\\n... PII DATAFRAME ...\\n\")\n",
    "# display(train_pii_df)\n",
    "\n",
    "# # Count the number of instances for each PII type\n",
    "# pii_type_counts = train_pii_df['pii_type'].value_counts()\n",
    "# print(\"\\n... PII TYPE COUNTS ...\\n\")\n",
    "# display(pii_type_counts.to_frame().T)\n",
    "\n",
    "# # Or aggregate to find the average PII length by type\n",
    "# average_pii_length_by_type = train_pii_df.groupby('pii_type')['pii_length'].mean()\n",
    "# print(\"\\n\\n... AVERAGE PII LENGTH (CHARS) BY TYPE ...\\n\")\n",
    "# display(average_pii_length_by_type.to_frame().T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Detect_PII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
